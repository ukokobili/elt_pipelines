{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "977779d7",
   "metadata": {},
   "source": [
    "# Building End To End ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "308b358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09c663fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creeate initail database connection( and instantiate if it doesn't exist already)\n",
    "conn = psycopg2.connect(database=\"chicago.db\",\n",
    "                        host=\"localhost\",\n",
    "                        user=\"root\",\n",
    "                        password=\"root\",\n",
    "                        port=\"5432\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0568031-9318-4bac-8ecb-f5933f0778ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate cursor object to execute any queries on the database and retrieve data. \n",
    "curr = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a605146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the schema\n",
    "curr.execute(\"\"\"\n",
    "    CREATE SCHEMA IF NOT EXISTS chicago_dmv;\n",
    "\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d3dcf18-5d7c-40b1-be2e-5ccf2b736981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating vehicle table\n",
    "vehicle = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS chicago_dmv.vehicle(\n",
    "        CRASH_UNIT_ID integer, \n",
    "        CRASH_ID text, \n",
    "        CRASH_DATE timestamp, \n",
    "        VEHICLE_ID integer, \n",
    "        VEHICLE_MAKE text, \n",
    "        VEHICLE_MODEL text, \n",
    "        VEHICLE_YEAR integer, \n",
    "        VEHICLE_TYPE text\n",
    "    );\n",
    "\"\"\"\n",
    "curr.execute(vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c25317db-c533-40cc-b01b-491c8ffbd21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating person table\n",
    "person = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS chicago_dmv.person(\n",
    "        PERSON_ID text, \n",
    "        CRASH_ID text, \n",
    "        CRASH_DATE timestamp, \n",
    "        PERSON_TYPE text, \n",
    "        VEHICLE_ID integer, \n",
    "        PERSON_SEX text, \n",
    "        PERSON_AGE integer\n",
    "    );\n",
    "\"\"\"\n",
    "curr.execute(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "272ab3b3-902f-4bf4-856a-183404533564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating person table\n",
    "time = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS chicago_dmv.time(\n",
    "        CRASH_DATE timestamp, \n",
    "        CRASH_ID text, \n",
    "        CRASH_HOUR integer, \n",
    "        CRASH_DAY_OF_WEEK integer, \n",
    "        CRASH_MONTH integer, \n",
    "        DATE_POLICE_NOTIFIED timestamp\n",
    "    );\n",
    "\"\"\"\n",
    "curr.execute(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30ea43fa-419b-4c71-bc6f-da84bafb6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating person table\n",
    "crash = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS chicago_dmv.crash(\n",
    "        CRASH_UNIT_ID integer, \n",
    "        CRASH_ID text, \n",
    "        PERSON_ID text, \n",
    "        VEHICLE_ID integer, \n",
    "        NUM_UNITS numeric, \n",
    "        TOTAL_INJURIES numeric \n",
    "    );\n",
    "\"\"\"\n",
    "curr.execute(crash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8996c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating person table\n",
    "drop = \"\"\"\n",
    "    DROP TABLE chicago_dmv.time;\n",
    "\"\"\"\n",
    "curr.execute(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69b2aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating person table\n",
    "drop = \"\"\"\n",
    "    SELECT * FROM chicago_dmv.crash LIMIT 10;\n",
    "\"\"\"\n",
    "curr.execute(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f03969e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(curr.execute(drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1a0637d-9447-444b-adcb-4cbe2c0c687a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Tables:\n",
      "chicago_dmv.vehicle\n",
      "chicago_dmv.person\n",
      "chicago_dmv.crash\n"
     ]
    }
   ],
   "source": [
    "# Query to get a list of all tables and their schemas\n",
    "query_all_tables = \"\"\"\n",
    "    SELECT table_schema, table_name\n",
    "    FROM information_schema.tables\n",
    "    WHERE table_schema NOT LIKE 'pg_%' AND table_schema != 'information_schema';\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "curr.execute(query_all_tables)\n",
    "\n",
    "# Fetch and print the results\n",
    "tables = curr.fetchall()\n",
    "print(\"List of Tables:\")\n",
    "for table in tables:\n",
    "    print(f\"{table[0]}.{table[1]}\")\n",
    "\n",
    "# Close the cursor and the connection\n",
    "curr.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5289d-0506-414d-8a7d-e77b99541a00",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c917487-668d-4524-8624-c0e82dba0d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependent modules\n",
    "import pandas as pd\n",
    "\n",
    "# extract data\n",
    "def extract_data(filepath: object) -> object:\n",
    "    \"\"\"\n",
    "       Simple Extract Function in Python with Error Handling\n",
    "       :param filepath: str, file path to CSV data\n",
    "       :output: pandas dataframe, extracted from CSV data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file and store it in a dataframe\n",
    "        df = pd.read_csv(filepath)\n",
    "\n",
    "    # Handle exception if any of the files are missing\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    # Handle any other exceptions\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bda89e-f206-43f2-adb3-1456b2c3f436",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bdab91-d414-4f63-9abf-8bd0add8527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "\n",
    "# transform data\n",
    "def transform_data(df: object) -> object:\n",
    "    \"\"\"\n",
    "       Simple Transformation Function in Python with Error Handling\n",
    "       :param df: pandas dataframe, extracted data\n",
    "       :output: pandas dataframe, transformed data\n",
    "    \"\"\"\n",
    "\n",
    "    # drop duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # replace missing values in numeric columns with the mean\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "    # replace missing values in categorical columns with the mode\n",
    "    df.fillna(df.mode().iloc[0], inplace=True)\n",
    "\n",
    "    # convert columns to appropriate data types\n",
    "    try:\n",
    "        df['CRASH_DATE'] = pd.to_datetime(df['CRASH_DATE'], format='%m/%d/%Y')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        df['POSTED_SPEED_LIMIT'] = df ['POSTED_SPEED_LIMIT'].astype('int32')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # merge the three dataframes into a single dataframe\n",
    "    merge_01_df = pd.merge(df, df2, on='CRASH_RECORD_ID')\n",
    "    all_data_df = pd.merge(merge_01_df, df3, on='CRASH_RECORD_ID')\n",
    "    \n",
    "    # drop unnecessary columns\n",
    "    df = df[['CRASH_UNIT_ID', 'CRASH_ID', 'CRASH_DATE', 'VEHICLE_ID', 'VEHICLE_MAKE', 'VEHICLE_MODEL',\n",
    "             'VEHICLE_YEAR', 'VEHICLE_TYPE', 'PERSON_ID', 'PERSON_TYPE', 'PERSON_SEX', 'PERSON_AGE',\n",
    "             'CRASH_HOUR', 'CRASH_DAY_OF_WEEK', 'CRASH_MONTH', 'DATE_POLICE_NOTIFIED']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a84d24-9655-4779-a3eb-169ed232c7d5",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b21fd9-a229-444e-860a-328813783a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant modules\n",
    "import duckdb as db\n",
    "\n",
    "# establish connection to the DuckDB database\n",
    "conn = db.connect('chicago.db')\n",
    "\n",
    "# create a cursor object for running SQL queries\n",
    "cur = conn.cursor()\n",
    "print('successful creation of cursor object.')\n",
    "\n",
    "\n",
    "# suggested continued learning: this function can be modified to be fully dynamic\n",
    "def load_data(df: object, duckdb_table: object, duckdb_schema: object) -> object:\n",
    "    \"\"\"\n",
    "    Load transformed data into respective DuckDB Table\n",
    "    :param cur: posgre cursor object\n",
    "    :return: cursor object\n",
    "    \"\"\"\n",
    "    insert_query = f\"INSERT INTO {duckdb_table} {duckdb_schema};\"\n",
    "\n",
    "    # insert transformed data into the DuckDB table\n",
    "    # TODO: REFACTOR TO MAKE SENSE - VERY SLOW / POOR USE OF CPUs\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        if duckdb_table == 'chicago_dmv.crash':\n",
    "            insert_values = (row['CRASH_UNIT_ID'],\n",
    "                              row['CRASH_ID'],\n",
    "                              row['PERSON_ID'],\n",
    "                              row['VEHICLE_ID'],\n",
    "                              row['NUM_UNITS'],\n",
    "                              row['TOTAL_INJURIES'])\n",
    "\n",
    "        elif duckdb_table == 'chicago_dmv.vehicle':\n",
    "            insert_values = (row['CRASH_UNIT_ID'],\n",
    "                              row['CRASH_ID'],\n",
    "                              row['CRASH_DATE'],\n",
    "                              row['VEHICLE_ID'],\n",
    "                              row['VEHICLE_MAKE'],\n",
    "                              row['VEHICLE_MODEL'],\n",
    "                              row['VEHICLE_YEAR'],\n",
    "                              row['VEHICLE_TYPE'])\n",
    "\n",
    "        elif duckdb_table == 'chicago_dmv.person':\n",
    "            insert_values = (row['PERSON_ID'],\n",
    "                              row['CRASH_ID'],\n",
    "                              row['CRASH_DATE'],\n",
    "                              row['PERSON_TYPE'],\n",
    "                              row['VEHICLE_ID'],\n",
    "                              row['PERSON_SEX'],\n",
    "                              row['PERSON_AGE'])\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'DuckDB Data Table {duckdb_table} does not exist in this pipeline.')\n",
    "\n",
    "        # Insert data int\n",
    "        cur.execute(insert_query, insert_values)\n",
    "\n",
    "    # Commit all changes to the database\n",
    "    conn.commit()\n",
    "\n",
    "def close_conn(cur):\n",
    "    \"\"\"\n",
    "    Closing DuckDB connection\n",
    "    :param cur: duckdb cursor object\n",
    "    :return: none\n",
    "    \"\"\"\n",
    "\n",
    "    # Close the cursor and database connection\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print('successful closing of cursor object.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46feb1fa-637f-4e85-97d9-11e61a6ad630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb as db\n",
    "\n",
    "# Establish connection to the DuckDB database\n",
    "conn = db.connect('chicago.db')\n",
    "\n",
    "# Create a cursor object for running SQL queries\n",
    "cur = conn.cursor()\n",
    "print('Successful creation of cursor object.')\n",
    "\n",
    "\n",
    "def load_data(df: object, duckdb_table: object, duckdb_schema: object) -> object:\n",
    "    \"\"\"\n",
    "    Load transformed data into respective DuckDB Table\n",
    "    :param df: pandas DataFrame\n",
    "    :param duckdb_table: DuckDB table name\n",
    "    :param duckdb_schema: DuckDB table schema\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct the insert query based on the table name\n",
    "    insert_query = f\"INSERT INTO {duckdb_table} {duckdb_schema}\"\n",
    "\n",
    "    # Convert pandas DataFrame to a list of tuples (suitable for parameterization)\n",
    "    data_list = df.values.tolist()\n",
    "\n",
    "    # Execute the parameterized insert query using the data list\n",
    "    cur.executemany(insert_query, data_list)\n",
    "\n",
    "    # Commit all changes to the database\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def close_conn(cur):\n",
    "    \"\"\"\n",
    "    Closing DuckDB connection\n",
    "    :param cur: duckdb cursor object\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # Close the cursor and database connection\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print('Successful closing of cursor object.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a48a126-83da-422b-b496-a015ee943211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant modules\n",
    "import duckdb as db\n",
    "\n",
    "# establish connection to the DuckDB database\n",
    "conn = db.connect('chicago.db')\n",
    "\n",
    "# create a cursor object for running SQL queries\n",
    "cur = conn.cursor()\n",
    "print('successful creation of cursor object.')\n",
    "\n",
    "\n",
    "# suggested continued learning: this function can be modified to be fully dynamic\n",
    "def load_data(df: object, duckdb_table: object, duckdb_schema: object) -> object:\n",
    "    \"\"\"\n",
    "    Load transformed data into respective DuckDB Table\n",
    "    :param cur: posgre cursor object\n",
    "    :return: cursor object\n",
    "    \"\"\"\n",
    "    # Prepare the INSERT INTO query with placeholders for values\n",
    "    insert_query = f\"INSERT INTO {duckdb_table} {duckdb_schema} VALUES ({', '.join(['?'] * len(df.columns))});\"\n",
    "\n",
    "    # Loop through DataFrame rows\n",
    "    for _, row in df.iterrows():\n",
    "        # Create a tuple of values from the DataFrame row\n",
    "        insert_values = tuple(row)\n",
    "\n",
    "        # Execute the prepared statement with the current row's values\n",
    "        cur.execute(insert_query, insert_values)\n",
    "\n",
    "    # Commit all changes to the database\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def close_conn(cur):\n",
    "    \"\"\"\n",
    "    Closing DuckDB connection\n",
    "    :param cur: duckdb cursor object\n",
    "    :return: none\n",
    "    \"\"\"\n",
    "    # Close the cursor and database connection\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print('successful closing of cursor object.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e39b0-047c-4b8b-a0da-d72cb9b75c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a command-line runnable pipeline\n",
    "from etl.extract import extract_data\n",
    "from etl.transform import transform_data\n",
    "import etl.load as load\n",
    "\n",
    "import yaml\n",
    "\n",
    "# import pipeline configuration\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config_data = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "def run_pipeline():\n",
    "    # Step 1: Extract data\n",
    "    crashes_df = extract_data(config_data['crash_filepath'])\n",
    "    vehicle_df = extract_data(config_data['vehicle_filepath'])\n",
    "    people_df = extract_data(config_data['people_filepath'])\n",
    "\n",
    "    # Step 2: Transform data\n",
    "    crashes_transformed_df = transform_data(crashes_df)\n",
    "    vehicle_transformed_df = transform_data(vehicle_df)\n",
    "    people_transformed_df = transform_data(people_df)\n",
    "\n",
    "    # Step 3: Load data\n",
    "    load.load_data(df=crashes_transformed_df,\n",
    "                   postgre_table=config_data['crash_table_PSQL'],\n",
    "                   postgre_schema=config_data['crash_insert_PSQL'])\n",
    "    load.load_data(df=vehicle_transformed_df,\n",
    "                   postgre_table=config_data['vehicle_table_PSQL'],\n",
    "                   postgre_schema=config_data['vehicle_insert_PSQL'])\n",
    "    load.load_data(df=people_transformed_df,\n",
    "                   postgre_table=config_data['people_table_PSQL'],\n",
    "                   postgre_schema=config_data['people_insert_PSQL'])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
